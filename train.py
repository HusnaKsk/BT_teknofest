import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import layers, models
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import f1_score
import os
import shutil
import random
from tensorflow.keras.models import load_model
import cv2

"""
# Veri artÄ±rma ve normalizasyon
train_datagen = ImageDataGenerator(
    rescale=1./255,  # 0-1 arasÄ±na Ã¶lÃ§ekle
    rotation_range=20,  # Rastgele dÃ¶ndÃ¼rme
    width_shift_range=0.1,  # GeniÅŸlik kaydÄ±rma
    height_shift_range=0.1,  # YÃ¼kseklik kaydÄ±rma
    shear_range=0.1,  # Kesme dÃ¶nÃ¼ÅŸÃ¼mÃ¼
    zoom_range=0.1,  # YakÄ±nlaÅŸtÄ±rma
    horizontal_flip=True  # Yatay Ã§evirme
)

test_datagen = ImageDataGenerator(rescale=1./255)  # Test seti iÃ§in sadece normalizasyon

# Train verisini yÃ¼kle
train_generator = train_datagen.flow_from_directory(
    'dataset/train',
    target_size=(224, 224),
    batch_size=32,
    class_mode='binary'
)

# Test verisini yÃ¼kle
test_generator = test_datagen.flow_from_directory(
    'dataset/test',
    target_size=(224, 224),
    batch_size=32,
    class_mode='binary'
    """
"""
)
# CNN modelini oluÅŸtur
model = models.Sequential([
    layers.Conv2D(32, (3,3), activation='relu', input_shape=(224,224,3)),
    layers.MaxPooling2D((2,2)),

    layers.Conv2D(64, (3,3), activation='relu'),
    layers.MaxPooling2D((2,2)),

    layers.Conv2D(128, (3,3), activation='relu'),
    layers.MaxPooling2D((2,2)),

    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.5),  # Overfitting'i azaltmak iÃ§in
    layers.Dense(1, activation='sigmoid')  # Binary classification iÃ§in
])

# Modeli derle
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Modelin Ã¶zetini yazdÄ±r
model.summary()

# Modeli eÄŸit
history = model.fit(
    train_generator,
    epochs=25,
    validation_data=test_generator
)
model.save('bt_inme_model.h5')
print("âœ… Model baÅŸarÄ±yla kaydedildi: bt_inme_model.h5")


# EÄŸitim doÄŸruluÄŸu ve kaybÄ± gÃ¶rselleÅŸtir
plt.plot(history.history['accuracy'], label='EÄŸitim DoÄŸruluÄŸu')
plt.plot(history.history['val_accuracy'], label='DoÄŸrulama DoÄŸruluÄŸu')
plt.xlabel('Epoch')
plt.ylabel('DoÄŸruluk')
plt.legend()
plt.show()

plt.plot(history.history['loss'], label='EÄŸitim KaybÄ±')
plt.plot(history.history['val_loss'], label='DoÄŸrulama KaybÄ±')
plt.xlabel('Epoch')
plt.ylabel('KayÄ±p')
plt.legend()
plt.show()

# Test verisini al
y_true = test_generator.classes  # GerÃ§ek etiketler
y_pred = model.predict(test_generator) > 0.5  # Modelin tahmini

# F1 Score hesapla
f1 = f1_score(y_true, y_pred)
print(f"âœ… F1 Score: {f1:.2f}")

"""

# EÄŸitilmiÅŸ modeli yÃ¼kle
model = load_model('bt_inme_model.h5')
print("âœ… Model baÅŸarÄ±yla yÃ¼klendi ve kullanÄ±ma hazÄ±r!")


# GÃ¶rÃ¼ntÃ¼yÃ¼ modele uygun hale getirme fonksiyonu
def predict_image(image_path):
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # GÃ¶rÃ¼ntÃ¼yÃ¼ gri tonlamaya Ã§evir
    img = cv2.resize(img, (224, 224))  # Modelin giriÅŸ boyutuna gÃ¶re yeniden boyutlandÄ±r
    img = np.expand_dims(img, axis=-1)  # Kanal boyutu ekle (Gray -> (224, 224, 1))
    img = np.expand_dims(img, axis=0)  # Batch boyutu ekle (1, 224, 224, 1)
    img = img / 255.0  # Normalizasyon yap

    # Model tahmini yap
    prediction = model.predict(img)[0][0]
    if prediction > 0.5:
        return f"âš ï¸ Ä°nme Var (Skor: {prediction:.2f})"
    else:
        return f"âœ… Ä°nme Yok (Skor: {prediction:.2f})"

# KullanÄ±cÄ±dan bir PNG dosyasÄ± iste ve sonucu gÃ¶ster
image_path = "test_image.png"  # Buraya test etmek istediÄŸin PNG dosyanÄ±n adÄ±nÄ± yaz
result = predict_image(image_path)
print(f"ğŸ§  Modelin Tahmini: {result}")





